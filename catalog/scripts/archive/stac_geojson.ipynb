{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5c73dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "from datetime import datetime, timezone\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7ed0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from https://storage.googleapis.com/swhm_data/public/cig_grid_wgs.geojson...\n"
     ]
    }
   ],
   "source": [
    "fc_url = \"https://storage.googleapis.com/swhm_data/public/cig_grid_wgs.geojson\"\n",
    "print(f\"Reading data from {fc_url}...\")\n",
    "gdf = gpd.read_file(fc_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebdc115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure the GeoDataFrame is not empty\n",
    "if gdf.empty:\n",
    "    print(\"Input GeoJSON is empty. Aborting.\")\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87107d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yn/15903z7124l3th5fm7wg0lgw0000gn/T/ipykernel_52328/2880513651.py:4: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  footprint_geom = mapping(gdf.unary_union.convex_hull)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract spatial and temporal metadata\n",
    "bounds = gdf.total_bounds\n",
    "bbox = [bounds, bounds, bounds, bounds]\n",
    "footprint_geom = mapping(gdf.unary_union.convex_hull)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fff8b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use current time as a placeholder for the item's datetime\n",
    "item_datetime = datetime.now(timezone.utc)\n",
    "\n",
    "# --- Step 2: Create the root Catalog and Collection ---\n",
    "# The Catalog is the top-level entry point\n",
    "catalog_id = \"vector-catalog-example\"\n",
    "catalog_description = \"A catalog of example vector datasets.\"\n",
    "catalog = pystac.Catalog(id=catalog_id, description=catalog_description)\n",
    "\n",
    "# The Collection groups related items and holds shared metadata\n",
    "collection_id = \"national-parks-collection\"\n",
    "collection_description = \"Boundaries of National Parks in the USA.\"\n",
    "collection_license = \"PDDL-1.0\" # Public Domain Dedication and License\n",
    "\n",
    "# Define the full extent of the collection\n",
    "spatial_extent = pystac.SpatialExtent(bboxes=[bbox])\n",
    "temporal_extent = pystac.TemporalExtent(intervals=[[item_datetime, None]])\n",
    "collection_extent = pystac.Extent(spatial=spatial_extent, temporal=temporal_extent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84f42cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&lt;Link rel=child target=&lt;Collection id=national-parks-collection&gt;&gt;"
      ],
      "text/plain": [
       "<Link rel=child target=<Collection id=national-parks-collection>>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog = pystac.Catalog.from_file('https://storage.googleapis.com/swhm_data/public/layers/raster/catalog.json')\n",
    "collection = pystac.Collection(\n",
    "    id=collection_id,\n",
    "    description=collection_description,\n",
    "    extent=collection_extent,\n",
    "    license=collection_license,\n",
    "    title=\"National Parks\"\n",
    ")\n",
    "\n",
    "# Add the collection as a child of the root catalog\n",
    "catalog.add_child(collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82e04eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cig_grid_wgs'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- Step 3: Create the STAC Item ---\n",
    "item_id = \"cig_grid_wgs\"\n",
    "\n",
    "item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92a25e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item = pystac.Item(\n",
    "    id=item_id,\n",
    "    geometry=footprint_geom,\n",
    "    bbox=bbox,\n",
    "    datetime=item_datetime,\n",
    "    properties={}, # Custom properties can be added here\n",
    "    collection=collection\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33fb87f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Step 4: Create the Asset and add Extensions ---\n",
    "asset_href = os.path.abspath(fc_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93ec73c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the main data asset\n",
    "asset = pystac.Asset(\n",
    "    href=asset_href,\n",
    "    media_type='application/geo+json', # pystac provides common media types\n",
    "    title=\"National Parks GeoJSON\",\n",
    "    roles=[\"data\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba441b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Enable and populate the Projection Extension\n",
    "proj_ext = pystac.extensions.projection.ProjectionExtension.ext(asset, add_if_missing=False)\n",
    "if gdf.crs:\n",
    "    proj_ext.epsg = gdf.crs.to_epsg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cca66da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Enable and populate the Table Extension to describe attributes\n",
    "# table_ext = pystac.extensions.table.TableExtension.ext(asset, add_if_missing=False)\n",
    "# columns = []\n",
    "# for col_name, dtype in gdf.dtypes.items():\n",
    "#     if col_name!= 'geometry': # Exclude the geometry column\n",
    "#         columns.append(\n",
    "#             {\n",
    "# \"name\": col_name,\n",
    "# \"type\": str(dtype),\n",
    "# \"description\": f\"Attribute column for {col_name}\"\n",
    "# }\n",
    "#         )\n",
    "# table_ext.columns = columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d49481d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add the fully described asset to the item\n",
    "item.add_asset(\"GeoJSON_data\", asset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1338c39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* <Catalog id=swhm-catalog>\n",
      "    * <Collection id=raster>\n",
      "      * <Item id=Age_of_Imperviousness>\n",
      "      * <Item id=Flow_Duration_Index>\n",
      "      * <Item id=HSPF_Land_Cover_Type>\n",
      "      * <Item id=Hydrologic_Response_Units>\n",
      "      * <Item id=Imperviousness>\n",
      "      * <Item id=Land_Cover>\n",
      "      * <Item id=Land_Use>\n",
      "      * <Item id=Population_Density>\n",
      "      * <Item id=Precipitation_mm>\n",
      "      * <Item id=Runoff_mm>\n",
      "      * <Item id=Slope>\n",
      "      * <Item id=Slope_Categories>\n",
      "      * <Item id=Soils>\n",
      "      * <Item id=Total_Copper_Concentration>\n",
      "      * <Item id=Total_Kjeldahl_Nitrogen_Concentration>\n",
      "      * <Item id=Total_Phosphorus_Concentration>\n",
      "      * <Item id=Total_Suspended_Solids_Concentration>\n",
      "      * <Item id=Total_Zinc_Concentration>\n",
      "      * <Item id=Traffic>\n",
      "      * <Item id=copper_concentration_ug_per_L>\n",
      "    * <Collection id=national-parks-collection>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CATALOG_JSON_DEST = \"https://storage.googleapis.com/swhm_data/public/layers/raster/\"\n",
    "catalog.normalize_hrefs(root_href=CATALOG_JSON_DEST)\n",
    "\n",
    "catalog.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8865202",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type ndarray is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m OUTPUT_DIR = \u001b[33m\"\u001b[39m\u001b[33m../../stac_catalog\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mcatalog\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpystac\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCatalogType\u001b[49m\u001b[43m.\u001b[49m\u001b[43mABSOLUTE_PUBLISHED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest_href\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# --- Step 5: Save the static catalog ---\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Set the HREFs to be relative and save to the output directory\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaving catalog to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/repos/swmh-stac-catalog/.venv/lib/python3.13/site-packages/pystac/catalog.py:981\u001b[39m, in \u001b[36mCatalog.save\u001b[39m\u001b[34m(self, catalog_type, dest_href, stac_io)\u001b[39m\n\u001b[32m    977\u001b[39m     rel_href = make_relative_href(child.self_href, \u001b[38;5;28mself\u001b[39m.self_href)\n\u001b[32m    978\u001b[39m     child_dest_href = make_absolute_href(\n\u001b[32m    979\u001b[39m         rel_href, dest_href, start_is_dir=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    980\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m981\u001b[39m     \u001b[43mchild\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdest_href\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild_dest_href\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstac_io\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstac_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    986\u001b[39m     child.save(stac_io=stac_io)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/repos/swmh-stac-catalog/.venv/lib/python3.13/site-packages/pystac/catalog.py:1022\u001b[39m, in \u001b[36mCatalog.save\u001b[39m\u001b[34m(self, catalog_type, dest_href, stac_io)\u001b[39m\n\u001b[32m   1018\u001b[39m     rel_href = make_relative_href(\u001b[38;5;28mself\u001b[39m.self_href, \u001b[38;5;28mself\u001b[39m.self_href)\n\u001b[32m   1019\u001b[39m     catalog_dest_href = make_absolute_href(\n\u001b[32m   1020\u001b[39m         rel_href, dest_href, start_is_dir=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1021\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msave_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_self_link\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_self_link\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdest_href\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcatalog_dest_href\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstac_io\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstac_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m catalog_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1028\u001b[39m     \u001b[38;5;28mself\u001b[39m.catalog_type = catalog_type\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/repos/swmh-stac-catalog/.venv/lib/python3.13/site-packages/pystac/stac_object.py:480\u001b[39m, in \u001b[36mSTACObject.save_object\u001b[39m\u001b[34m(self, include_self_link, dest_href, stac_io)\u001b[39m\n\u001b[32m    475\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m STACError(\n\u001b[32m    476\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSelf HREF must be set before saving without an explicit dest_href.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m         )\n\u001b[32m    478\u001b[39m     dest_href = self_href\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m \u001b[43mstac_io\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdest_href\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude_self_link\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_self_link\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/repos/swmh-stac-catalog/.venv/lib/python3.13/site-packages/pystac/stac_io.py:260\u001b[39m, in \u001b[36mStacIO.save_json\u001b[39m\u001b[34m(self, dest, json_dict, *args, **kwargs)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave_json\u001b[39m(\n\u001b[32m    241\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    242\u001b[39m     dest: HREF,\n\u001b[32m   (...)\u001b[39m\u001b[32m    245\u001b[39m     **kwargs: Any,\n\u001b[32m    246\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    247\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Write a dict to the given URI as JSON.\u001b[39;00m\n\u001b[32m    248\u001b[39m \n\u001b[32m    249\u001b[39m \u001b[33;03m    See :func:`StacIO.write_text <pystac.StacIO.write_text>` for usage of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    258\u001b[39m \u001b[33;03m            :meth:`StacIO.json_dumps`.\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     txt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjson_dumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m     \u001b[38;5;28mself\u001b[39m.write_text(dest, txt)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/repos/swmh-stac-catalog/.venv/lib/python3.13/site-packages/pystac/stac_io.py:132\u001b[39m, in \u001b[36mStacIO.json_dumps\u001b[39m\u001b[34m(self, json_dict, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m orjson.dumps(json_dict, option=orjson.OPT_INDENT_2, **kwargs).decode(\n\u001b[32m    129\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    130\u001b[39m     )\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py:238\u001b[39m, in \u001b[36mdumps\u001b[39m\u001b[34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONEncoder\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/encoder.py:200\u001b[39m, in \u001b[36mJSONEncoder.encode\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    202\u001b[39m     chunks = \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/encoder.py:261\u001b[39m, in \u001b[36mJSONEncoder.iterencode\u001b[39m\u001b[34m(self, o, _one_shot)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     _iterencode = _make_iterencode(\n\u001b[32m    258\u001b[39m         markers, \u001b[38;5;28mself\u001b[39m.default, _encoder, indent, floatstr,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mself\u001b[39m.key_separator, \u001b[38;5;28mself\u001b[39m.item_separator, \u001b[38;5;28mself\u001b[39m.sort_keys,\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m.skipkeys, _one_shot)\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type ndarray is not JSON serializable"
     ]
    }
   ],
   "source": [
    "\n",
    "OUTPUT_DIR = \"../../stac_catalog\"\n",
    "catalog.save(pystac.CatalogType.ABSOLUTE_PUBLISHED, dest_href=OUTPUT_DIR)\n",
    "# --- Step 5: Save the static catalog ---\n",
    "# Set the HREFs to be relative and save to the output directory\n",
    "print(f\"Saving catalog to {output_dir}...\")\n",
    "catalog.normalize_hrefs(output_dir)\n",
    "catalog.save(catalog_type=pystac.CatalogType.ABSOLUTE_PUBLISHED,dest_href=OUTPUT_DIR)\n",
    "print(\"Catalog generation complete.\")\n",
    "catalog.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10d732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs(\"./temp_data\")\n",
    "output_stac_dir = \"./stac_output\"\n",
    "\n",
    "    # Run the creation process\n",
    "#create_vector_stac_catalog(\"https://storage.googleapis.com/swhm_data/public/cig_grid_wgs.geojson\", output_stac_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d16da53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create dummy data for the example\n",
    "    if not os.path.exists(\"./temp_data\"):\n",
    "        os.makedirs(\"./temp_data\")\n",
    "    \n",
    "    dummy_fc_url = \"./temp_data/national_parks.gpkg\"\n",
    "    d = {'name': ['Yellowstone', 'Yosemite'],\n",
    "         'state': ['WY', 'CA'],\n",
    "         'geometry': [gpd.points_from_xy(, ).buffer(0.5), \n",
    "                      gpd.points_from_xy([-1], [-2]).buffer(0.5)]}\n",
    "    gdf = gpd.GeoDataFrame(d, crs=\"EPSG:4326\")\n",
    "    gdf.to_file(dummy_fc_url, driver=\"GPKG\")\n",
    "\n",
    "    # Define output directory\n",
    "    output_stac_dir = \"./stac_output\"\n",
    "\n",
    "    # Run the creation process\n",
    "    create_vector_stac_catalog(dummy_fc_url, output_stac_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0630c801",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # --- Step 2: Create the root Catalog and Collection ---\n",
    "catalog = pystac.Catalog(\n",
    "        id=\"vector-catalog-example\",\n",
    "        description=\"A catalog of example vector datasets.\"\n",
    "    )\n",
    "\n",
    "def create_vector_stac_catalog(fc_url: str, output_dir: str):\n",
    "    \"\"\"\n",
    "    Generates a STAC Catalog for a single GeoJSON vector file.\n",
    "\n",
    "    Args:\n",
    "        fc_url (str): The full path to the input GeoJSON file.\n",
    "        output_dir (str): The directory where the STAC catalog will be saved.\n",
    "    \"\"\"\n",
    "    # --- Step 1: Read vector data and extract core metadata ---\n",
    "    print(f\"Reading data from {fc_url}...\")\n",
    "    gdf = gpd.read_file(fc_url)\n",
    "\n",
    "    if gdf.empty:\n",
    "        print(\"Input GeoJSON is empty. Aborting.\")\n",
    "        return\n",
    "\n",
    "    bounds = gdf.total_bounds\n",
    "    bbox = [list(bounds)]\n",
    "    footprint_geom = mapping(gdf.unary_union.convex_hull)\n",
    "    item_datetime = datetime.now(timezone.utc)\n",
    "\n",
    "\n",
    "\n",
    "    spatial_extent = pystac.SpatialExtent(bboxes=bbox)\n",
    "    temporal_extent = pystac.TemporalExtent(intervals=[[item_datetime, None]])\n",
    "    collection_extent = pystac.Extent(spatial=spatial_extent, temporal=temporal_extent)\n",
    "\n",
    "    collection = pystac.Collection(\n",
    "        id=\"national-parks-collection\",\n",
    "        description=\"Boundaries of National Parks in the USA.\",\n",
    "        extent=collection_extent,\n",
    "        license=\"PDDL-1.0\",\n",
    "        title=\"National Parks\"\n",
    "    )\n",
    "\n",
    "    catalog.add_child(collection)\n",
    "\n",
    "    # --- Step 3: Create the STAC Item ---\n",
    "    item_id = os.path.splitext(os.path.basename(fc_url))[0]\n",
    "\n",
    "    item = pystac.Item(\n",
    "        id=item_id,\n",
    "        geometry=footprint_geom,\n",
    "        bbox=list(bounds),\n",
    "        datetime=item_datetime,\n",
    "        properties={},\n",
    "    )\n",
    "\n",
    "    collection.add_item(item)\n",
    "\n",
    "    # --- Step 4: Create the Asset and add Extensions ---\n",
    "    asset_href = os.path.abspath(fc_url)\n",
    "    asset = pystac.Asset(\n",
    "        href=asset_href,\n",
    "        media_type='application/geo+json',\n",
    "        title=\"National Parks GeoJSON\",\n",
    "        roles=[\"data\"]\n",
    "    )\n",
    "\n",
    "    # First, add the asset to the item\n",
    "    item.add_asset(\"GeoJSON_data\", asset)\n",
    "\n",
    "    # Retrieve asset with owner set\n",
    "    asset = item.assets[\"GeoJSON_data\"]\n",
    "\n",
    "    # Add projection extension\n",
    "    proj_ext = projection.ProjectionExtension.ext(asset, add_if_missing=True)\n",
    "    if gdf.crs:\n",
    "        epsg = gdf.crs.to_epsg()\n",
    "        if epsg:\n",
    "            proj_ext.epsg = epsg\n",
    "\n",
    "    # Add table extension\n",
    "    table_ext = table.TableExtension.ext(asset, add_if_missing=True)\n",
    "    columns = []\n",
    "    for col_name, dtype in gdf.dtypes.items():\n",
    "        if col_name != 'geometry':\n",
    "            columns.append({\n",
    "                \"name\": col_name,\n",
    "                \"type\": str(dtype),\n",
    "                \"description\": f\"Attribute column for {col_name}\"\n",
    "            })\n",
    "    table_ext.columns = columns\n",
    "\n",
    "    # --- Step 5: Save the catalog ---\n",
    "    print(f\"Saving catalog to {output_dir}...\")\n",
    "    catalog.normalize_hrefs(output_dir)\n",
    "    catalog.save(catalog_type=pystac.CatalogType.SELF_CONTAINED)\n",
    "    print(\"Catalog generation complete.\")\n",
    "    catalog.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bbfac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from https://storage.googleapis.com/swhm_data/public/cig_grid_wgs.geojson...\n",
      "Saving catalog to ./stac_output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yn/15903z7124l3th5fm7wg0lgw0000gn/T/ipykernel_52328/2439452340.py:19: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  footprint_geom = mapping(gdf.unary_union.convex_hull)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalog generation complete.\n",
      "* <Catalog id=vector-catalog-example>\n",
      "    * <Collection id=national-parks-collection>\n",
      "      * <Item id=cig_grid_wgs>\n"
     ]
    }
   ],
   "source": [
    "from pystac.extensions import projection, table\n",
    "output_stac_dir = \"./stac_output\"\n",
    "create_vector_stac_catalog(\"https://storage.googleapis.com/swhm_data/public/cig_grid_wgs.geojson\", output_stac_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
