{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCP Bucket Crawler and Catalog Generator\n",
    "\n",
    "This notebook crawls a GCP storage bucket to discover vector and raster data, then generates collections and a comprehensive catalog.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. Install required packages:\n",
    "   ```bash\n",
    "   pip install google-cloud-storage\n",
    "   ```\n",
    "\n",
    "2. Set up authentication:\n",
    "   - Service account: `export GOOGLE_APPLICATION_CREDENTIALS='path/to/key.json'`\n",
    "   - Or use: `gcloud auth application-default login`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "from urllib.parse import urljoin\n",
    "import os\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Update these values for your specific bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - update these values for your specific bucket\n",
    "bucket_name = \"swhm_data\"  # Just the bucket name, not the full URL\n",
    "prefix = \"public/layers/\"  # Path prefix within the bucket\n",
    "project_id = None  # Set your GCP project ID if needed\n",
    "\n",
    "print(f\"Bucket: {bucket_name}\")\n",
    "print(f\"Prefix: {prefix}\")\n",
    "print(f\"Project ID: {project_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCP Bucket Crawler Class\n",
    "\n",
    "This class handles the connection to GCP and crawling of the bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCPBucketCrawler:\n",
    "    def __init__(self, bucket_name: str, prefix: str = \"\", project_id: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the crawler with GCP bucket details.\n",
    "        \n",
    "        Args:\n",
    "            bucket_name: Name of the GCP storage bucket (e.g., 'swhm_data')\n",
    "            prefix: Prefix to filter objects (e.g., 'public/layers/')\n",
    "            project_id: GCP project ID (optional, will use default if not provided)\n",
    "        \"\"\"\n",
    "        self.bucket_name = bucket_name\n",
    "        self.prefix = prefix\n",
    "        self.project_id = project_id\n",
    "        self.vectors = []\n",
    "        self.rasters = []\n",
    "        \n",
    "        # Initialize the GCS client\n",
    "        try:\n",
    "            if project_id:\n",
    "                self.client = storage.Client(project=project_id)\n",
    "            else:\n",
    "                self.client = storage.Client()\n",
    "            self.bucket = self.client.bucket(bucket_name)\n",
    "            print(f\"Successfully connected to bucket: {bucket_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing GCS client: {e}\")\n",
    "            print(\"Make sure you have proper authentication set up:\")\n",
    "            print(\"1. Set GOOGLE_APPLICATION_CREDENTIALS environment variable\")\n",
    "            print(\"2. Or run 'gcloud auth application-default login'\")\n",
    "            self.client = None\n",
    "            self.bucket = None\n",
    "        \n",
    "    def crawl_bucket(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Crawl the GCP bucket to discover all vectors and rasters.\n",
    "        Returns a dictionary with discovered items.\n",
    "        \"\"\"\n",
    "        if not self.client or not self.bucket:\n",
    "            print(\"No valid GCS client available, creating sample data...\")\n",
    "            return self._create_sample_data()\n",
    "            \n",
    "        print(f\"Crawling bucket '{self.bucket_name}' with prefix '{self.prefix}'...\")\n",
    "        \n",
    "        try:\n",
    "            # List all blobs in the bucket with the specified prefix\n",
    "            blobs = self.bucket.list_blobs(prefix=self.prefix)\n",
    "            \n",
    "            blob_count = 0\n",
    "            for blob in blobs:\n",
    "                blob_count += 1\n",
    "                self._process_blob(blob)\n",
    "                \n",
    "            print(f\"Processed {blob_count} objects from bucket\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error crawling bucket: {e}\")\n",
    "            return self._create_sample_data()\n",
    "            \n",
    "        return {\n",
    "            'vectors': self.vectors,\n",
    "            'rasters': self.rasters,\n",
    "            'total_items': len(self.vectors) + len(self.rasters)\n",
    "        }\n",
    "    \n",
    "    def _process_blob(self, blob):\n",
    "        \"\"\"Process a single blob to determine if it's a vector or raster.\"\"\"\n",
    "        blob_name = blob.name\n",
    "        blob_path = Path(blob_name)\n",
    "        \n",
    "        # Skip directories (blobs ending with '/')\n",
    "        if blob_name.endswith('/'):\n",
    "            return\n",
    "            \n",
    "        # Check for vector files\n",
    "        if 'vectors/' in blob_name and blob_path.suffix.lower() in ['.geojson', '.json']:\n",
    "            self._add_vector_item(blob)\n",
    "            \n",
    "        # Check for raster files  \n",
    "        elif 'rasters/' in blob_name and blob_path.suffix.lower() in ['.tiff', '.tif', '.gtiff']:\n",
    "            self._add_raster_item(blob)\n",
    "    \n",
    "    def _add_vector_item(self, blob):\n",
    "        \"\"\"Add a vector item to the collection.\"\"\"\n",
    "        blob_path = Path(blob.name)\n",
    "        item_name = blob_path.stem\n",
    "        \n",
    "        # Create public URL\n",
    "        public_url = f\"https://storage.googleapis.com/{self.bucket_name}/{blob.name}\"\n",
    "        \n",
    "        vector_item = {\n",
    "            'name': item_name,\n",
    "            'filename': blob.name,\n",
    "            'url': public_url,\n",
    "            'type': 'vector',\n",
    "            'format': 'GeoJSON',\n",
    "            'size_bytes': blob.size,\n",
    "            'content_type': blob.content_type,\n",
    "            'created': blob.time_created.isoformat() if blob.time_created else None,\n",
    "            'updated': blob.updated.isoformat() if blob.updated else None,\n",
    "            'discovered_at': datetime.now().isoformat(),\n",
    "            'etag': blob.etag,\n",
    "            'md5_hash': blob.md5_hash\n",
    "        }\n",
    "        \n",
    "        self.vectors.append(vector_item)\n",
    "        print(f\"Found vector: {item_name}\")\n",
    "    \n",
    "    def _add_raster_item(self, blob):\n",
    "        \"\"\"Add a raster item to the collection.\"\"\"\n",
    "        blob_path = Path(blob.name)\n",
    "        item_name = blob_path.stem\n",
    "        \n",
    "        # Create public URL\n",
    "        public_url = f\"https://storage.googleapis.com/{self.bucket_name}/{blob.name}\"\n",
    "        \n",
    "        raster_item = {\n",
    "            'name': item_name,\n",
    "            'filename': blob.name,\n",
    "            'url': public_url,\n",
    "            'type': 'raster',\n",
    "            'format': 'GeoTIFF',\n",
    "            'size_bytes': blob.size,\n",
    "            'content_type': blob.content_type,\n",
    "            'created': blob.time_created.isoformat() if blob.time_created else None,\n",
    "            'updated': blob.updated.isoformat() if blob.updated else None,\n",
    "            'discovered_at': datetime.now().isoformat(),\n",
    "            'etag': blob.etag,\n",
    "            'md5_hash': blob.md5_hash\n",
    "        }\n",
    "        \n",
    "        self.rasters.append(raster_item)\n",
    "        print(f\"Found raster: {item_name}\")\n",
    "    \n",
    "    def get_blob_info(self, blob_name: str) -> Optional[Dict]:\n",
    "        \"\"\"Get detailed information about a specific blob.\"\"\"\n",
    "        if not self.bucket:\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            blob = self.bucket.blob(blob_name)\n",
    "            if blob.exists():\n",
    "                return {\n",
    "                    'name': blob.name,\n",
    "                    'size': blob.size,\n",
    "                    'content_type': blob.content_type,\n",
    "                    'created': blob.time_created.isoformat() if blob.time_created else None,\n",
    "                    'updated': blob.updated.isoformat() if blob.updated else None,\n",
    "                    'etag': blob.etag,\n",
    "                    'md5_hash': blob.md5_hash,\n",
    "                    'public_url': f\"https://storage.googleapis.com/{self.bucket_name}/{blob.name}\"\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting blob info for {blob_name}: {e}\")\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    def _create_sample_data(self):\n",
    "        \"\"\"Create sample data structure when bucket can't be crawled directly.\"\"\"\n",
    "        print(\"Creating sample data structure...\")\n",
    "        \n",
    "        base_url = f\"https://storage.googleapis.com/{self.bucket_name}\"\n",
    "        \n",
    "        # Sample vectors based on your structure\n",
    "        sample_vectors = [\n",
    "            {\n",
    "                'name': 'vector1',\n",
    "                'filename': f'{self.prefix}vectors/vector1/vector1.geojson',\n",
    "                'url': f\"{base_url}/{self.prefix}vectors/vector1/vector1.geojson\",\n",
    "                'type': 'vector',\n",
    "                'format': 'GeoJSON',\n",
    "                'size_bytes': None,\n",
    "                'content_type': 'application/geo+json',\n",
    "                'created': None,\n",
    "                'updated': None,\n",
    "                'discovered_at': datetime.now().isoformat(),\n",
    "                'etag': None,\n",
    "                'md5_hash': None\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Sample rasters based on your structure\n",
    "        sample_rasters = [\n",
    "            {\n",
    "                'name': 'raster1',\n",
    "                'filename': f'{self.prefix}rasters/raster1/raster1.tiff',\n",
    "                'url': f\"{base_url}/{self.prefix}rasters/raster1/raster1.tiff\",\n",
    "                'type': 'raster',\n",
    "                'format': 'GeoTIFF',\n",
    "                'size_bytes': None,\n",
    "                'content_type': 'image/tiff',\n",
    "                'created': None,\n",
    "                'updated': None,\n",
    "                'discovered_at': datetime.now().isoformat(),\n",
    "                'etag': None,\n",
    "                'md5_hash': None\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        self.vectors = sample_vectors\n",
    "        self.rasters = sample_rasters\n",
    "        \n",
    "        return {\n",
    "            'vectors': self.vectors,\n",
    "            'rasters': self.rasters,\n",
    "            'total_items': len(self.vectors) + len(self.rasters)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catalog Generator Class\n",
    "\n",
    "This class generates STAC-compliant collections and catalogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatalogGenerator:\n",
    "    def __init__(self, crawler_data: Dict):\n",
    "        \"\"\"Initialize with data from the crawler.\"\"\"\n",
    "        self.data = crawler_data\n",
    "        \n",
    "    def generate_vector_collection(self) -> Dict:\n",
    "        \"\"\"Generate a vector collection.\"\"\"\n",
    "        collection = {\n",
    "            \"type\": \"Collection\",\n",
    "            \"id\": \"swhm-vectors\",\n",
    "            \"title\": \"SWHM Vector Collection\",\n",
    "            \"description\": \"Collection of vector datasets from SWHM data bucket\",\n",
    "            \"keywords\": [\"vectors\", \"geojson\", \"swhm\"],\n",
    "            \"license\": \"proprietary\",\n",
    "            \"extent\": {\n",
    "                \"spatial\": {\n",
    "                    \"bbox\": [[-180, -90, 180, 90]]  # Global bbox - update with actual bounds\n",
    "                },\n",
    "                \"temporal\": {\n",
    "                    \"interval\": [[None, None]]\n",
    "                }\n",
    "            },\n",
    "            \"providers\": [\n",
    "                {\n",
    "                    \"name\": \"SWHM Data\",\n",
    "                    \"roles\": [\"producer\", \"processor\", \"host\"],\n",
    "                    \"url\": \"https://storage.googleapis.com/swhm_data/\"\n",
    "                }\n",
    "            ],\n",
    "            \"items\": []\n",
    "        }\n",
    "        \n",
    "        # Add vector items\n",
    "        for vector in self.data['vectors']:\n",
    "            item = {\n",
    "                \"type\": \"Feature\",\n",
    "                \"id\": vector['name'],\n",
    "                \"properties\": {\n",
    "                    \"title\": vector['name'].replace('_', ' ').title(),\n",
    "                    \"description\": f\"Vector dataset: {vector['name']}\",\n",
    "                    \"created\": vector['discovered_at'],\n",
    "                    \"updated\": vector['discovered_at']\n",
    "                },\n",
    "                \"geometry\": None,  # Would need to extract from actual GeoJSON\n",
    "                \"bbox\": None,  # Would need to calculate from geometry\n",
    "                \"assets\": {\n",
    "                    \"data\": {\n",
    "                        \"href\": vector['url'],\n",
    "                        \"type\": \"application/geo+json\",\n",
    "                        \"title\": \"GeoJSON data\",\n",
    "                        \"roles\": [\"data\"],\n",
    "                        \"file:size\": vector.get('size_bytes'),\n",
    "                        \"file:checksum\": vector.get('md5_hash')\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            collection[\"items\"].append(item)\n",
    "            \n",
    "        return collection\n",
    "    \n",
    "    def generate_raster_collection(self) -> Dict:\n",
    "        \"\"\"Generate a raster collection.\"\"\"\n",
    "        collection = {\n",
    "            \"type\": \"Collection\",\n",
    "            \"id\": \"swhm-rasters\",\n",
    "            \"title\": \"SWHM Raster Collection\",\n",
    "            \"description\": \"Collection of raster datasets from SWHM data bucket\",\n",
    "            \"keywords\": [\"rasters\", \"geotiff\", \"swhm\"],\n",
    "            \"license\": \"proprietary\",\n",
    "            \"extent\": {\n",
    "                \"spatial\": {\n",
    "                    \"bbox\": [[-180, -90, 180, 90]]  # Global bbox - update with actual bounds\n",
    "                },\n",
    "                \"temporal\": {\n",
    "                    \"interval\": [[None, None]]\n",
    "                }\n",
    "            },\n",
    "            \"providers\": [\n",
    "                {\n",
    "                    \"name\": \"SWHM Data\",\n",
    "                    \"roles\": [\"producer\", \"processor\", \"host\"],\n",
    "                    \"url\": \"https://storage.googleapis.com/swhm_data/\"\n",
    "                }\n",
    "            ],\n",
    "            \"items\": []\n",
    "        }\n",
    "        \n",
    "        # Add raster items\n",
    "        for raster in self.data['rasters']:\n",
    "            item = {\n",
    "                \"type\": \"Feature\",\n",
    "                \"id\": raster['name'],\n",
    "                \"properties\": {\n",
    "                    \"title\": raster['name'].replace('_', ' ').title(),\n",
    "                    \"description\": f\"Raster dataset: {raster['name']}\",\n",
    "                    \"created\": raster['discovered_at'],\n",
    "                    \"updated\": raster['discovered_at']\n",
    "                },\n",
    "                \"geometry\": None,  # Would need to extract from raster metadata\n",
    "                \"bbox\": None,  # Would need to calculate from raster bounds\n",
    "                \"assets\": {\n",
    "                    \"data\": {\n",
    "                        \"href\": raster['url'],\n",
    "                        \"type\": \"image/tiff; application=geotiff\",\n",
    "                        \"title\": \"GeoTIFF data\",\n",
    "                        \"roles\": [\"data\"],\n",
    "                        \"file:size\": raster.get('size_bytes'),\n",
    "                        \"file:checksum\": raster.get('md5_hash')\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            collection[\"items\"].append(item)\n",
    "            \n",
    "        return collection\n",
    "    \n",
    "    def generate_master_catalog(self, vector_collection: Dict, raster_collection: Dict) -> Dict:\n",
    "        \"\"\"Generate the master catalog containing all collections.\"\"\"\n",
    "        catalog = {\n",
    "            \"type\": \"Catalog\",\n",
    "            \"id\": \"swhm-data-catalog\",\n",
    "            \"title\": \"SWHM Data Catalog\",\n",
    "            \"description\": \"Master catalog for SWHM vector and raster datasets\",\n",
    "            \"stac_version\": \"1.0.0\",\n",
    "            \"created\": datetime.now().isoformat(),\n",
    "            \"updated\": datetime.now().isoformat(),\n",
    "            \"keywords\": [\"swhm\", \"vectors\", \"rasters\", \"geospatial\"],\n",
    "            \"providers\": [\n",
    "                {\n",
    "                    \"name\": \"SWHM Data\",\n",
    "                    \"roles\": [\"producer\", \"processor\", \"host\"],\n",
    "                    \"url\": \"https://storage.googleapis.com/swhm_data/\"\n",
    "                }\n",
    "            ],\n",
    "            \"links\": [\n",
    "                {\n",
    "                    \"rel\": \"self\",\n",
    "                    \"href\": \"./catalog.json\",\n",
    "                    \"type\": \"application/json\",\n",
    "                    \"title\": \"SWHM Data Catalog\"\n",
    "                },\n",
    "                {\n",
    "                    \"rel\": \"child\",\n",
    "                    \"href\": \"./vectors/collection.json\",\n",
    "                    \"type\": \"application/json\",\n",
    "                    \"title\": \"Vector Collection\"\n",
    "                },\n",
    "                {\n",
    "                    \"rel\": \"child\",\n",
    "                    \"href\": \"./rasters/collection.json\",\n",
    "                    \"type\": \"application/json\",\n",
    "                    \"title\": \"Raster Collection\"\n",
    "                }\n",
    "            ],\n",
    "            \"collections\": [\n",
    "                {\n",
    "                    \"id\": vector_collection['id'],\n",
    "                    \"title\": vector_collection['title'],\n",
    "                    \"description\": vector_collection['description'],\n",
    "                    \"href\": \"./vectors/collection.json\"\n",
    "                },\n",
    "                {\n",
    "                    \"id\": raster_collection['id'],\n",
    "                    \"title\": raster_collection['title'],\n",
    "                    \"description\": raster_collection['description'],\n",
    "                    \"href\": \"./rasters/collection.json\"\n",
    "                }\n",
    "            ],\n",
    "            \"summaries\": {\n",
    "                \"total_items\": self.data['total_items'],\n",
    "                \"vector_items\": len(self.data['vectors']),\n",
    "                \"raster_items\": len(self.data['rasters']),\n",
    "                \"formats\": [\"GeoJSON\", \"GeoTIFF\"]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "Helper function to save JSON files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(data: Dict, filepath: str):\n",
    "    \"\"\"Save data to JSON file with pretty formatting.\"\"\"\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"Saved: {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Crawler\n",
    "\n",
    "Create the crawler instance and connect to the GCP bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize crawler\n",
    "crawler = GCPBucketCrawler(bucket_name, prefix, project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl the Bucket\n",
    "\n",
    "Start the bucket crawling process to discover vector and raster data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crawl the bucket\n",
    "print(\"Starting bucket crawl...\")\n",
    "crawl_data = crawler.crawl_bucket()\n",
    "\n",
    "print(f\"Found {len(crawl_data['vectors'])} vectors and {len(crawl_data['rasters'])} rasters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Results\n",
    "\n",
    "Show a summary of the discovered data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display discovered vectors\n",
    "print(\"\\n=== DISCOVERED VECTORS ===\")\n",
    "for i, vector in enumerate(crawl_data['vectors'], 1):\n",
    "    print(f\"{i}. {vector['name']} ({vector['format']})\")\n",
    "    print(f\"   URL: {vector['url']}\")\n",
    "    if vector['size_bytes']:\n",
    "        print(f\"   Size: {vector['size_bytes']:,} bytes\")\n",
    "    print()\n",
    "\n",
    "# Display discovered rasters\n",
    "print(\"\\n=== DISCOVERED RASTERS ===\")\n",
    "for i, raster in enumerate(crawl_data['rasters'], 1):\n",
    "    print(f\"{i}. {raster['name']} ({raster['format']})\")\n",
    "    print(f\"   URL: {raster['url']}\")\n",
    "    if raster['size_bytes']:\n",
    "        print(f\"   Size: {raster['size_bytes']:,} bytes\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Collections and Catalog\n",
    "\n",
    "Create the STAC collections and master catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate collections and catalog\n",
    "generator = CatalogGenerator(crawl_data)\n",
    "\n",
    "# Generate collections\n",
    "print(\"Generating vector collection...\")\n",
    "vector_collection = generator.generate_vector_collection()\n",
    "\n",
    "print(\"Generating raster collection...\")\n",
    "raster_collection = generator.generate_raster_collection()\n",
    "\n",
    "# Generate master catalog\n",
    "print(\"Generating master catalog...\")\n",
    "master_catalog = generator.generate_master_catalog(vector_collection, raster_collection)\n",
    "\n",
    "print(\"\\nâœ… All collections and catalog generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview Generated Catalog\n",
    "\n",
    "Display a preview of the generated master catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display catalog summary\n",
    "print(\"=== MASTER CATALOG SUMMARY ===\")\n",
    "print(f\"Title: {master_catalog['title']}\")\n",
    "print(f\"Description: {master_catalog['description']}\")\n",
    "print(f\"STAC Version: {master_catalog['stac_version']}\")\n",
    "print(f\"Total Items: {master_catalog['summaries']['total_items']}\")\n",
    "print(f\"Vector Items: {master_catalog['summaries']['vector_items']}\")\n",
    "print(f\"Raster Items: {master_catalog['summaries']['raster_items']}\")\n",
    "print(f\"Formats: {', '.join(master_catalog['summaries']['formats'])}\")\n",
    "\n",
    "print(\"\\n=== COLLECTIONS ===\")\n",
    "for collection in master_catalog['collections']:\n",
    "    print(f\"- {collection['title']}: {collection['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Catalog Files\n",
    "\n",
    "Save all generated collections and catalogs to JSON files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all files\n",
    "print(\"Saving catalog files...\")\n",
    "save_json(master_catalog, \"catalog/catalog.json\")\n",
    "save_json(vector_collection, \"catalog/vectors/collection.json\")\n",
    "save_json(raster_collection, \"catalog/rasters/collection.json\")\n",
    "\n",
    "# Save summary with enhanced metadata\n",
    "summary = {\n",
    "    \"crawl_summary\": {\n",
    "        \"bucket_name\": bucket_name,\n",
    "        \"prefix\": prefix,\n",
    "        \"crawl_time\": datetime.now().isoformat(),\n",
    "        \"total_items\": crawl_data['total_items'],\n",
    "        \"vectors_found\": len(crawl_data['vectors']),\n",
    "        \"rasters_found\": len(crawl_data['rasters'])\n",
    "    },\n",
    "    \"discovered_vectors\": crawl_data['vectors'],\n",
    "    \"discovered_rasters\": crawl_data['rasters']\n",
    "}\n",
    "save_json(summary, \"catalog/crawl_summary.json\")\n",
    "\n",
    "print(f\"\\nâœ… Catalog generation complete!\")\n",
    "print(f\"   - Master catalog: catalog/catalog.json\")\n",
    "print(f\"   - Vector collection: catalog/vectors/collection.json\")\n",
    "print(f\"   - Raster collection: catalog/rasters/collection.json\")\n",
    "print(f\"   - Crawl summary: catalog/crawl_summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Individual Blob Information\n",
    "\n",
    "Get detailed information about specific blobs in the bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Get information about a specific blob\n",
    "# Uncomment and modify the blob name as needed\n",
    "\n",
    "# blob_name = \"public/layers/vectors/example/example.geojson\"\n",
    "# blob_info = crawler.get_blob_info(blob_name)\n",
    "# \n",
    "# if blob_info:\n",
    "#     print(f\"\\n=== BLOB INFO: {blob_name} ===\")\n",
    "#     for key, value in blob_info.items():\n",
    "#         print(f\"{key}: {value}\")\n",
    "# else:\n",
    "#     print(f\"Blob not found or error accessing: {blob_name}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ To get info about a specific blob, uncomment and modify the code above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export as Python Script\n",
    "\n",
    "If you want to run this as a standalone script, here's the complete code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a standalone Python script\n",
    "script_content = '''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "GCP Bucket Crawler and Catalog Generator\n",
    "Generated from Jupyter notebook\n",
    "\"\"\"\n",
    "\n",
    "# This script combines all the classes and functions from above\n",
    "# You can copy the individual cells above to create a complete script\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the crawler.\"\"\"\n",
    "    # Configuration\n",
    "    bucket_name = \"swhm_data\"\n",
    "    prefix = \"public/layers/\"\n",
    "    project_id = None\n",
    "    \n",
    "    # Initialize and run crawler\n",
    "    crawler = GCPBucketCrawler(bucket_name, prefix, project_id)\n",
    "    crawl_data = crawler.crawl_bucket()\n",
    "    \n",
    "    # Generate catalog\n",
    "    generator = CatalogGenerator(crawl_data)\n",
    "    vector_collection = generator.generate_vector_collection()\n",
    "    raster_collection = generator.generate_raster_collection()\n",
    "    master_catalog = generator.generate_master_catalog(vector_collection, raster_collection)\n",
    "    \n",
    "    # Save files\n",
    "    save_json(master_catalog, \"catalog/catalog.json\")\n",
    "    save_json(vector_collection, \"catalog/vectors/collection.json\")\n",
    "    save_json(raster_collection, \"catalog/rasters/collection.json\")\n",
    "    \n",
    "    print(\"âœ… Catalog generation complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Save the script\n",
    "with open('gcp_bucket_crawler.py', 'w') as f:\n",
    "    # Note: In a real scenario, you'd include all the class definitions here\n",
    "    f.write(script_content)\n",
    "    \n",
    "print(\"ðŸ“„ Standalone script template saved as 'gcp_bucket_crawler.py'\")\n",
    "print(\"   Note: You'll need to copy the class definitions from the cells above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "Common issues and solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check authentication status\n",
    "print(\"=== TROUBLESHOOTING GUIDE ===\")\n",
    "print(\"\\n1. Authentication Issues:\")\n",
    "print(\"   - Set GOOGLE_APPLICATION_CREDENTIALS environment variable\")\n",
    "print(\"   - Or run: gcloud auth application-default login\")\n",
    "print(\"   - Ensure service account has Storage Object Viewer permissions\")\n",
    "\n",
    "print(\"\\n2. Package Installation:\")\n",
    "print(\"   - pip install google-cloud-storage\")\n",
    "\n",
    "print(\"\\n3. Bucket Access:\")\n",
    "print(\"   - Verify bucket name is correct\")\n",
    "print(\"   - Check if bucket is publicly accessible or requires authentication\")\n",
    "print(\"   - Verify prefix path exists in the bucket\")\n",
    "\n",
    "print(\"\\n4. File Detection:\")\n",
    "print(\"   - Vector files should be in 'vectors/' subdirectory with .geojson/.json extension\")\n",
    "print(\"   - Raster files should be in 'rasters/' subdirectory with .tiff/.tif/.gtiff extension\")\n",
    "\n",
    "# Check current environment\n",
    "print(\"\\n=== CURRENT ENVIRONMENT ===\")\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "try:\n",
    "    import google.cloud.storage\n",
    "    print(f\"google-cloud-storage: Available\")\n",
    "except ImportError:\n",
    "    print(f\"google-cloud-storage: NOT INSTALLED\")\n",
    "    print(\"   Run: pip install google-cloud-storage\")\n",
    "\n",
    "# Check environment variables\n",
    "gcp_creds = os.environ.get('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "if gcp_creds:\n",
    "    print(f\"GOOGLE_APPLICATION_CREDENTIALS: {gcp_creds}\")\n",
    "else:\n",
    "    print(\"GOOGLE_APPLICATION_CREDENTIALS: Not set\")\n",
    "    print(\"   Consider setting this environment variable\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}